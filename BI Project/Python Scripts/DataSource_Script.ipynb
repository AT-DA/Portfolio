{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install SQLAlchemy #used to export a pandas DF to MYSQL table \n",
    "#pip install mysql-connector-python #used to connect MYSQL to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from datetime import date, datetime, timedelta\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_conn = 'mysql+mysqlconnector://root:root@localhost:3306/bi_project_db' #connection string for MYSQL alchemy\n",
    "\n",
    "#ill use this connection for filling the lookup tables using the pandas df.to_sql method because it will allow\n",
    "#me to overwrite the tables before inserting \n",
    "#ill lose referential integrity because the pandas import method overrides the original table structure with the \n",
    "#columns data types of the data frame that will be imported. but it wont matter because i will take the referential integrity\n",
    "#constraint into consideration becauase i will be filling the lookup tables manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vehicle_DF.to_sql(name = 'vehicle', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace', index = False)\n",
    "#example on how to import using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(host='localhost',\n",
    "                                         database='bi_project_db',\n",
    "                                         user='root',\n",
    "                                         password='root'\n",
    "                              )\n",
    "\n",
    "#ill use this connection to fill the transactional tables because it will keep the original table structure, so the primary\n",
    "#key column of the transaction tables will auto increment each time a record is inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def Product():\\n\\n    cols_list = Product_DF.columns.to_list()\\n    list_to_string = ', '.join(cols_list)\\n    columns = '(' + list_to_string + ')'\\n    Insert_String = 'insert into bi_project_db.product \\n '           +  columns  + '\\n' +          'Values (%s, %s, %s, %s, %s)'\\n    \\n\\n    for index, record in Product_DF.iterrows():\\n        cursor.execute(Insert_String, tuple(record))\\n        conn.commit()\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def Product():\n",
    "\n",
    "    cols_list = Product_DF.columns.to_list()\n",
    "    list_to_string = ', '.join(cols_list)\n",
    "    columns = '(' + list_to_string + ')'\n",
    "    Insert_String = 'insert into bi_project_db.product \\n ' \\\n",
    "          +  columns  + '\\n' + \\\n",
    "         'Values (%s, %s, %s, %s, %s)'\n",
    "    \n",
    "\n",
    "    for index, record in Product_DF.iterrows():\n",
    "        cursor.execute(Insert_String, tuple(record))\n",
    "        conn.commit()\n",
    "'''\n",
    "\n",
    "#Example on how to import using mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vehicle():\n",
    "    \n",
    "    ID = list(range(1,4))\n",
    "\n",
    "    Brand = ['Tesla', 'Tesla', 'Tesla']\n",
    "\n",
    "    Model = ['Tesla Truck', 'Tesla Truck', 'Tesla Truck']\n",
    "\n",
    "    Year_Of_Model = [2021, 2021, 2021]\n",
    "\n",
    "    Plate_Number = ['DFA124', 'IGK181', 'KKR920']\n",
    "\n",
    "    License_Number = [76908487, 76908465, 96908442]\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'ID': ID, 'Brand': Brand, 'Model': Model, 'Year_Of_Model': Year_Of_Model, 'Plate_Number': Plate_Number, \\\n",
    "            'License_Number':License_Number\n",
    "          }\n",
    "\n",
    "    Vehicle_DF = pd.DataFrame(Dic)\n",
    "    \n",
    "    Vehicle_DF.to_sql(name = 'vehicle', con = pandas_conn, schema = 'bi_project_db', \n",
    "                      if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vehicle_DF.to_sql(name = 'vehicle', con = conn, schema = 'bi_project_db', if_exists = 'replace', index = True)\n",
    "#Use this method to export data using pandas.\n",
    "#i did not use this method because it changes the table's structure, and the tables lose referential integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw_Material Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Raw_Material():\n",
    "    \n",
    "    ID = list(range(1,8))\n",
    "\n",
    "    \n",
    "    Name = ['Copper', 'Lithium', 'Tin', 'Silver', 'Gold', 'Nickel', 'Aluminum']\n",
    "\n",
    "    Category = ['Metals', 'Metals', 'Metals', 'Metals', 'Metals', 'Metals', 'Metals']\n",
    "\n",
    "    Cost_Price = [5, 9, 13, 14, 11, 12, 14]\n",
    "\n",
    "    Unit_Of_Measure = ['KG', 'KG', 'KG', 'KG', 'KG', 'KG', 'KG' ]\n",
    "\n",
    "    Unit_Value = [5, 5, 5, 5, 5, 5, 5]\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'ID': ID, 'Name': Name, 'Category': Category, 'Cost_Price': Cost_Price, 'Unit_Of_Measure': Unit_Of_Measure, \\\n",
    "            'Unit_Value': Unit_Value\n",
    "          }\n",
    "\n",
    "\n",
    "    Raw_Material_DF = pd.DataFrame(Dic)\n",
    "    \n",
    "    Raw_Material_DF.to_sql(name = 'raw_material', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Product():\n",
    "    \n",
    "    ID = list(range(1,17))\n",
    "\n",
    "    Name = [\n",
    "            'Iphone', 'Alienware Laptop', 'Washing Machine', 'Lenovo Laptop', 'Samsung Mobile', 'One Plus Mobile', \\\n",
    "            'Xiaomi Mobile', 'Samsung Laptop', 'PS5', 'Toshiba Laptop', 'Iphone', 'Huawei Mobile', \\\n",
    "            'Canon Camera', 'Speakers', 'HP Laptop', 'Oven'\n",
    "           ]\n",
    "\n",
    "    Color = [\n",
    "            '-', '-', '-', '-', '-', '-', '-', '-', \\\n",
    "            '-', '-', '-', '-', '-', '-', '-', '-'\n",
    "            ]\n",
    "\n",
    "    Category = [\n",
    "               'Mobiles', 'Laptops', 'Appliances', 'Laptops', 'Mobiles', 'Mobiles', \\\n",
    "               'Mobiles', 'Laptops', 'Video Games', 'Laptops', 'Mobiles', 'Mobiles',  \\\n",
    "               'Cameras', 'TV, Audio & Video', 'Laptops', 'Appliances'\n",
    "               ]\n",
    "\n",
    "    Cost_Price =  [\n",
    "                    150, 160, 310, 310, 310, 200, 500, 500, 130, 160, 170, 310, 310, 300, 200, 160\n",
    "                  ]\n",
    "\n",
    "    Selling_Price = [\n",
    "                        200, 200, 350, 350, 350, 200, 600, 600, 250, 200, 200, 350, 350, 350, 200, 200\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "             'ID': ID, 'Name': Name, 'Color': Color, 'Category': Category, 'Cost_Price':Cost_Price, 'Selling_Price': Selling_Price\n",
    "          }\n",
    "\n",
    "\n",
    "    Product_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Product_DF.to_sql(name = 'product', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Department Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Department():\n",
    "    \n",
    "    ID = list(range(1,7))\n",
    "\n",
    "    Name = ['Sales', 'Purchases', 'Operations', 'HR', 'Finance', 'IT']\n",
    "\n",
    "\n",
    "    Dic = {'ID': ID, 'Name': Name}\n",
    "\n",
    "\n",
    "    Department_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Department_DF.to_sql(name = 'department', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promotion Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Promotion():\n",
    "    \n",
    "    ID = [1,2]\n",
    "\n",
    "    Code = ['10% discount', '20% discount']\n",
    "\n",
    "    Type = ['Discount', 'Discount']\n",
    "\n",
    "    Amount = [0.1, 0.2]\n",
    "\n",
    "    Valid_From = ['2022-06-06', '2099-06-06']\n",
    "\n",
    "    Valid_To = ['2022-06-06', '2099-06-06']\n",
    "\n",
    "\n",
    "    Dic = {'ID': ID, 'Code': Code, 'Type': Type, 'Amount': Amount, 'Valid_From': Valid_From, 'Valid_To': Valid_To}\n",
    "\n",
    "\n",
    "    Promotion_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Promotion_DF.to_sql(name = 'promotion', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payment_Type Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Payment_Type():\n",
    "    \n",
    "    ID = list(range(1,3))\n",
    "\n",
    "    Description = ['Credit', 'Cash']\n",
    "\n",
    "\n",
    "    Dic = {'ID': ID, 'Description': Description}\n",
    "\n",
    "\n",
    "    Payment_Type_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Payment_Type_DF.to_sql(name = 'payment_type', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order_Method Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Order_Method():\n",
    "    \n",
    "    ID = list(range(1,3))\n",
    "\n",
    "    Description = ['Online', 'Offline']\n",
    "\n",
    "\n",
    "    Dic = {'ID': ID, 'Description': Description}\n",
    "\n",
    "\n",
    "    Order_Method_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Order_Method_DF.to_sql(name = 'order_method', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return_Reason Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Return_Reason():\n",
    "    \n",
    "    ID = list(range(1,5))\n",
    "\n",
    "    Description = [\n",
    "                    'Faulty product', 'Other', 'Change In Plans', 'Need Different Size'\n",
    "                  ]\n",
    "\n",
    "\n",
    "    Dic = {'ID': ID, 'Description': Description}\n",
    "\n",
    "\n",
    "    Return_Reason_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Return_Reason_DF.to_sql(name = 'return_reason', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Country():\n",
    "    \n",
    "    ID = list(range(1,2))\n",
    "\n",
    "    Name = ['DC Universe']\n",
    "\n",
    "\n",
    "    Dic = {'ID': ID, 'Name': Name}\n",
    "\n",
    "\n",
    "    Country_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Country_DF.to_sql(name = 'country', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def City():\n",
    "    \n",
    "    ID = list(range(1,6))\n",
    "\n",
    "    Name = ['Gotham City', 'Metropolis', 'Smallville', 'Star City', 'Central City']\n",
    "\n",
    "    CountryID = [1, 1, 1, 1, 1]\n",
    "\n",
    "\n",
    "    Dic = {'ID': ID, 'Name': Name, 'CountryID': CountryID}\n",
    "\n",
    "\n",
    "    City_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    City_DF.to_sql(name = 'city', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Area():\n",
    "    \n",
    "    ID = list(range(1,12))\n",
    "\n",
    "    Name = [\n",
    "            'Crime Alley', 'The Batcave', 'Arkham Asylum', 'GCPD', 'Blackgate', 'Ace Chemicals', 'Wayne Enterprises', \\\n",
    "            'Daily Planet', 'LexCorp', 'STAR Labs', 'Wayne Tech'\n",
    "            ]\n",
    "\n",
    "    CityID = [1, 2, 3, 4, 5, 1, 1, 2, 2, 4, 5]\n",
    "\n",
    "\n",
    "    Dic = {'ID': ID, 'Name': Name, 'CityID': CityID}\n",
    "\n",
    "\n",
    "    Area_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Area_DF.to_sql(name = 'area', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Employee():\n",
    "    \n",
    "    ID = list(range(1,4))\n",
    "\n",
    "    First_Name = ['Hal', 'Barry', 'Arthur']\n",
    "\n",
    "    Last_Name = ['Jordan', 'Allen', 'Curry']\n",
    "\n",
    "    Phone_Number = [11110111, 202222, 33333333]\n",
    "\n",
    "    Email = ['Hal@xyz.com', 'Barry@xyz.com', 'Arthur@xyz.com']\n",
    "\n",
    "    AreaID = [1, 2, 1]\n",
    "\n",
    "    DepartmentID = [1, 1, 1]\n",
    "\n",
    "    ManagerID = [1, 1, 2]\n",
    "\n",
    "    Level = [1, 2, 3]\n",
    "\n",
    "    National_ID = [123456, 654321, 987789]\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'ID': ID, 'First_Name': First_Name, 'Last_Name': Last_Name, 'Phone_Number': Phone_Number , 'Email': Email , \\\n",
    "            'AreaID': AreaID , 'DepartmentID': DepartmentID , 'ManagerID': ManagerID , 'Level': Level , 'National_ID': National_ID \n",
    "          }\n",
    "\n",
    "\n",
    "    Employee_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Employee_DF.to_sql(name = 'employee', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Customer():\n",
    "    \n",
    "    ID = list(range(1,9))\n",
    "\n",
    "    First_Name = ['Peter', 'Bruce', 'Harry', 'Tony', 'Clark', 'Diana', 'Harley', 'Barbara']\n",
    "\n",
    "    Last_Name = ['Parker', 'Wayne', 'Potter', 'Stark', 'Kent', 'Prince', 'Quinn', 'Gordon']\n",
    "\n",
    "    Phone_Number = [11111121, 22222231, 33333341, 11111151, 22222261, 33333371, 11111181, 11111191 ]\n",
    "\n",
    "    Email = [\n",
    "                'Parker@xyz.com', 'Wayne@xyz.com', 'Potter@xyz.com', 'Stark@xyz.com', \\\n",
    "                'Kent@xyz.com', 'Prince@xyz.com', 'Quinn@xyz.com', 'Gordon@xyz.com'\n",
    "            ]\n",
    "\n",
    "    AreaID = [1, 2, 3, 4, 1, 2, 3, 4]\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'ID': ID, 'First_Name': First_Name, 'Last_Name': Last_Name, 'Phone_Number': Phone_Number , \\\n",
    "            'Email': Email , 'AreaID': AreaID \n",
    "          }\n",
    "\n",
    "\n",
    "    Customer_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Customer_DF.to_sql(name = 'customer', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplier Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Supplier():\n",
    "    \n",
    "    ID = list(range(1,7))\n",
    "\n",
    "    Name = ['LiveSale Supply', 'Retail Distribution Bros', 'Wholesale Imported', 'SupplySpace Global', \\\n",
    "            'Metals Trading', 'Leads Group']\n",
    "\n",
    "    Phone_Number = [11110118, 202228, 33333338, 33333334, 33333337, 33333332 ]\n",
    "    \n",
    "    Email = ['LiveSaleSupply@xyz.com', 'RetailDistributionBros@xyz.com', 'WholesaleImported@xyz.com', \\\n",
    "             'SupplyspaceGlobal@xyz.com', 'MetalsTrading@xyz.com', 'LeadsGroup@xyz.com' ]\n",
    "    \n",
    "    AreaID = [1, 2, 3, 2, 1, 3]\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'ID': ID, 'Name': Name, 'Phone_Number': Phone_Number , \\\n",
    "            'Email': Email , 'AreaID': AreaID \n",
    "          }\n",
    "\n",
    "\n",
    "    Supplier_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Supplier_DF.to_sql(name = 'supplier', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Branch():\n",
    "    \n",
    "    ID = list(range(1,4))\n",
    "\n",
    "    Name = ['Store1', 'Store2', 'Warehouse1']\n",
    "\n",
    "    Type = ['Store', 'Store', 'Warehouse']\n",
    "    \n",
    "    Square_Meters = [150, 220, 240]\n",
    "\n",
    "    Monthly_Rent = [10000, 8000, 5000]\n",
    "\n",
    "    Average_Monthly_Expenses = [2500, 2000, 1500]\n",
    "\n",
    "    AreaID = [1, 1, 1]\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'ID': ID, 'Name': Name, 'Type': Type, 'Square_Meters': Square_Meters, 'Monthly_Rent': Monthly_Rent, \\\n",
    "            'Average_Monthly_Expenses': Average_Monthly_Expenses, 'AreaID': AreaID \\\n",
    "\n",
    "          }\n",
    "\n",
    "\n",
    "    Branch_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Branch_DF.to_sql(name = 'branch', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Route():\n",
    "    \n",
    "    ID = list(range(1,9))\n",
    "\n",
    "    Code = ['F1', 'C3', 'M7', 'M4', 'C1', 'F9', 'M1', 'C1']\n",
    "\n",
    "    From_Branch = [1, 2, 3, 1, 2, 3, 1, 2]\n",
    "\n",
    "    Last_Destination_Stop = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "    Total_Kilometers_Distance = [64, 82, 34, 92, 56, 51, 43, 29]\n",
    "\n",
    "    Average_Minutes_Duration = [62, 80, 32, 90, 54, 49, 41, 27]\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'ID': ID, 'Code': Code, 'From_Branch': From_Branch, 'Last_Destination_Stop': Last_Destination_Stop , \\\n",
    "            'Total_Kilometers_Distance': Total_Kilometers_Distance , 'Average_Minutes_Duration': Average_Minutes_Duration \n",
    "          }\n",
    "\n",
    "\n",
    "    Route_DF = pd.DataFrame(Dic)\n",
    "\n",
    "    Route_DF.to_sql(name = 'route', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trip Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new trips\n",
    "\n",
    "#this function creates new trips for the entered date. it takes an input parameter as the trip date. \n",
    "#current_date is the default parameter.\n",
    "#a total of 4 trips are created for each day with 4 different times. each day cannot have more than 4 trips. this is handled\n",
    "#with an if condition. the function returns a dataframe with the newly created trips.\n",
    "\n",
    "def Create_Trips(P_Date = date.today() + timedelta(days = 1)): \n",
    "    #added timedelta days = 1 to make sure that there are trips that cover the order creation date.\n",
    "    #check the query of Order_Date_With_Trip_DF in the function Create_Orders()\n",
    "\n",
    "    query_string = 'select count(*) \\\n",
    "             from bi_project_db.trip \\\n",
    "             where cast(expected_start_date as date) = ' + '\\'' + str(P_Date) + '\\''\n",
    "    #creates a dataframe that checks the number of trips in the day of the input date parameter.\n",
    "\n",
    "    trips = pd.read_sql_query(query_string, pandas_conn)\n",
    "    trips = trips.iloc[0,0]\n",
    "\n",
    "    if trips == 0: #if there are no trips, the rest of the code will excecute.\n",
    "\n",
    "       \n",
    "        Vehicles = pd.read_sql_query('select id from vehicle', pandas_conn)\n",
    "        Vehicles = Vehicles['id'].to_list()\n",
    "\n",
    "        Employees = pd.read_sql_query('select id from employee', pandas_conn)\n",
    "        Employees = Employees['id'].to_list()\n",
    "\n",
    "        Routes = pd.read_sql_query('select id from route', pandas_conn)\n",
    "        Routes = Routes['id'].to_list()\n",
    "\n",
    "        RouteID = [random.choice(Routes) for i in list(range(4))]\n",
    "\n",
    "        RouteID_DF = pd.DataFrame(RouteID, columns = ['id']) \n",
    "        Route_And_AVG_Time_DF = pd.read_sql_query('select id, Average_Minutes_Duration from route', pandas_conn)\n",
    "        #get the trip average minutes duration because it will be used to calculate the column expected_end_date\n",
    "        trip_with_minutes_df = RouteID_DF.merge(Route_And_AVG_Time_DF, how='left', left_on = 'id', right_on = 'id')\n",
    "\n",
    "        trip_start_times = ['00:00:00', '06:00:00', '12:00:00', '18:00:00'] #create 4 trips each day with 4 fixed start times\n",
    "\n",
    "        Expected_Start_Date_List = [datetime.strptime(str(P_Date) + ' ' + i,'%Y-%m-%d %H:%M:%S')  for i in trip_start_times]\n",
    "        #concatenate the entered input parameter with the 4 trip start times to create 4 trips each day with an interval of 6\n",
    "        #hours between each\n",
    "\n",
    "        Expected_Start_Date_DF = pd.DataFrame(Expected_Start_Date_List, columns = ['Expected_Start_Date'])\n",
    "        Expected_Start_Date_DF = Expected_Start_Date_DF.join(trip_with_minutes_df) #join the trip expected start date with the \n",
    "        #route average minutes to calculate the trip expected_end_date\n",
    "\n",
    "        Expected_End_Date = []\n",
    "        for index, record in Expected_Start_Date_DF.iterrows():\n",
    "            avg_minutes_duration = record['Average_Minutes_Duration']\n",
    "            Expected_Start_Date = record['Expected_Start_Date']\n",
    "            Expected_Start_Date = Expected_Start_Date + timedelta(minutes = avg_minutes_duration)\n",
    "            Expected_End_Date.append(Expected_Start_Date)\n",
    "            #expected_end_date = expected_start_date + the trip route average minutes duration \n",
    "\n",
    "        VehicleID = [random.choice(Vehicles) for i in list(range(4))]\n",
    "\n",
    "        EmployeeID = [random.choice(Employees) for i in list(range(4))]\n",
    "\n",
    "        RouteID = RouteID\n",
    "\n",
    "        Expected_Start_Date = Expected_Start_Date_List #it is already created in the steps above\n",
    "\n",
    "        Actual_Start_Date = [None, None, None, None] #set the values as None temporarily. when the current_datetime >=\n",
    "        #the expected_start_date, the actual_start_date will be generated. this will be handled by the function\n",
    "        #Trip_Actual_Start_Date()\n",
    "\n",
    "        Expected_End_Date = Expected_End_Date #it is already created in the steps above\n",
    "\n",
    "        Actual_End_Date = [None, None, None, None] #set the values as None temporarily. when the current_datetime >=\n",
    "        #the expected_emdnd_date, the actual_end_date will be generated. this will be handled by the function\n",
    "        #Trip_Actual_End_Date()\n",
    "\n",
    "\n",
    "        Dic = {\n",
    "                'VehicleID': VehicleID, 'EmployeeID': EmployeeID, 'RouteID': RouteID, \\\n",
    "                'Expected_Start_Date': Expected_Start_Date, 'Actual_Start_Date': Actual_Start_Date,\n",
    "                'Expected_End_Date': Expected_End_Date, 'Actual_End_Date': Actual_End_Date\n",
    "              }\n",
    "\n",
    "\n",
    "        Trip_DF = pd.DataFrame(Dic)\n",
    "        \n",
    "        return Trip_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the new trips to the trips table. this function takes the trips DF as an input. it does not return anything.\n",
    "\n",
    "def Insert_Trips(Trip_DF):\n",
    "    \n",
    "    if Trip_DF is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "    \n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                        database='bi_project_db',\n",
    "                                        user='root',\n",
    "                                        password='root'\n",
    "                                        )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        cols_list = Trip_DF.columns.to_list()\n",
    "        list_to_string = ', '.join(cols_list)\n",
    "        columns = '(' + list_to_string + ')'\n",
    "        Insert_String = 'insert into bi_project_db.trip \\n ' \\\n",
    "        +  columns  + '\\n' + \\\n",
    "        'Values (%s, %s, %s, %s, %s, %s, %s )'\n",
    "\n",
    "        for index, record in Trip_DF.iterrows():\n",
    "            cursor.execute(Insert_String, tuple(record))\n",
    "            conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the actual_start_date column. this function updates the trips table by replacing None in the Actual_Start_Date column\n",
    "#with a datetime value. this function does not take any input. this function does not return anything.\n",
    "\n",
    "def Trip_Actual_Start_Date():\n",
    "    \n",
    "    #get trips that do not have actual_start_date\n",
    "    Trip_DF = pd.read_sql_query('select * from trip where actual_start_date is null', pandas_conn)\n",
    "    \n",
    "    if Trip_DF.empty == True:\n",
    "        pass\n",
    "    else:\n",
    "    \n",
    "        #check if the current_date passed the time of the expected_start_date\n",
    "        condition = Trip_DF['Expected_Start_Date'].apply(lambda x: datetime.now() > x)\n",
    "\n",
    "        changes_df = Trip_DF.loc[condition, ['ID','Expected_Start_Date']]\n",
    "\n",
    "        Actual_Start_Date = []\n",
    "\n",
    "        minutes_delay_list = list(range(1,35)) #enerate randomly 1-35mnutes which will be added the to expected_start_date\n",
    "        #to get the actual start_date\n",
    "\n",
    "        for index, record in changes_df.iterrows():\n",
    "            minutes_delay = random.choice(minutes_delay_list)\n",
    "            ID = record['ID']\n",
    "            Expected_Start_Date = record['Expected_Start_Date']\n",
    "            Expected_Start_Date = Expected_Start_Date + timedelta(minutes = minutes_delay)\n",
    "            Actual_Start_Date.append([ID, Expected_Start_Date])\n",
    "\n",
    "\n",
    "        #the trip id will be used to update the trips table because it is the unique identifier\n",
    "        Actual_Start_Date_DF = pd.DataFrame(Actual_Start_Date, columns = ['ID', 'Actual_Start_Date'])\n",
    "\n",
    "        #export the trips with the actual_start_time to MYSQL because they will be used to update the trips table\n",
    "        Actual_Start_Date_DF.to_sql(name = 'temp', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                                   index = False)\n",
    "\n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                                 database='bi_project_db',\n",
    "                                                 user='root',\n",
    "                                                 password='root'\n",
    "                                      )\n",
    "\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "\n",
    "        sql_statement = 'UPDATE trip \\\n",
    "               inner join temp ON (trip.id = temp.id) \\\n",
    "               SET trip.Actual_Start_Date = temp.Actual_Start_Date;'\n",
    "\n",
    "        cursor.execute(sql_statement)\n",
    "        conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the actual_end_date column. this function updates the trips table by replacing None in the Actual_End_Date column\n",
    "#with a datetime value. this function does not take any input. this function does not return anything.\n",
    "#refer to the function Trip_Actual_Start_Date(). it has a similar functionality as this function, but this function updates\n",
    "#the column Actual_End_Date.\n",
    "\n",
    "def Trip_Actual_End_Date():\n",
    "\n",
    "    Trip_DF = pd.read_sql_query('select * from trip where actual_end_date is null', pandas_conn)\n",
    "    \n",
    "    if Trip_DF.empty == True:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        Route_DF = pd.read_sql_query('select id, Average_Minutes_Duration from route', pandas_conn)\n",
    "\n",
    "        condition = Trip_DF['Expected_End_Date'].apply(lambda x: datetime.now() > x)\n",
    "\n",
    "        changes_df = Trip_DF.loc[condition, ['ID','Actual_Start_Date', 'RouteID']]\n",
    "\n",
    "        trip_with_route_df = changes_df.merge(Route_DF, how='left', left_on = 'RouteID', right_on = 'id')\n",
    "\n",
    "        trip_with_route_df = trip_with_route_df[['ID', 'Actual_Start_Date', 'Average_Minutes_Duration']]\n",
    "\n",
    "        Actual_End_Date_List = []\n",
    "\n",
    "\n",
    "\n",
    "        for index, record in trip_with_route_df.iterrows():\n",
    "            Average_Minutes_Duration = record['Average_Minutes_Duration']\n",
    "            trip_actual_duration = random.uniform(0.65, 1.35) * Average_Minutes_Duration\n",
    "            #random.uniform generates a random decimal number between 0.65 and 1.35.\n",
    "            #0.65 * average minutes duraition means that the trip took only 65% of the average duration,\n",
    "            #so the trip will arrive early 35% earlier (1-0.65 = 0.35)\n",
    "            #1.35 * average minutes duraition means that the trip took 35% more time that the average duration,\n",
    "            #so the trip will arrive 35% more late (1-1.35 = -0.35)\n",
    "            ID = record['ID']\n",
    "            Actual_Start_Date = record['Actual_Start_Date']\n",
    "            Actual_End_Date = Actual_Start_Date + timedelta(minutes = trip_actual_duration)\n",
    "            Actual_End_Date_List.append([ID, Actual_End_Date])\n",
    "\n",
    "\n",
    "        Actual_End_Date_DF = pd.DataFrame(Actual_End_Date_List, columns = ['ID', 'Actual_End_Date'])\n",
    "        Actual_End_Date_DF.to_sql(name = 'temp', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                                   index = False)\n",
    "\n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                                 database='bi_project_db',\n",
    "                                                 user='root',\n",
    "                                                 password='root'\n",
    "                                      )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        sql_statement = 'UPDATE trip \\\n",
    "               inner join temp ON (trip.id = temp.id) \\\n",
    "               SET trip.Actual_End_Date = temp.Actual_End_Date;'\n",
    "\n",
    "        cursor.execute(sql_statement)\n",
    "        conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales_Order And Sales_Order_Details Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new orders. #this function creates new orders for the entered date. it takes an input parameter as the order date. \n",
    "#current_date is the default parameter. #the function returns a dataframe with the order information\n",
    "\n",
    "def Create_Orders(P_Date = date.today()):\n",
    "    Numbers_Of_Orders_List = list(range(5,15))\n",
    "    Number_Of_Orders = random.choice(Numbers_Of_Orders_List)\n",
    "    Ratings_List = list(range(1,6))\n",
    "\n",
    "    Hours_List = list(range(0,24))\n",
    "    Mins_Secs_List = list(range(1,60))\n",
    "\n",
    "    Order_Date = []\n",
    "    for i in range(Number_Of_Orders):\n",
    "        Rand_Hr = str(random.choice(Hours_List))\n",
    "        Rand_Min = str(random.choice(Mins_Secs_List))\n",
    "        Rand_Sec = str(random.choice(Mins_Secs_List))\n",
    "        date_i = datetime.strptime(str(P_Date) + ' ' + Rand_Hr + ':' + Rand_Min + ':' + Rand_Sec ,'%Y-%m-%d %H:%M:%S')\n",
    "        #concatenate the entered date with random hours, minutes and seconds to create a random order date for today\n",
    "        Order_Date.append(date_i)\n",
    "\n",
    "    Order_Date_DF =  pd.DataFrame(Order_Date, columns = ['Order_Date'])\n",
    "    Order_Date_DF.to_sql(name = 'temp', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace', index = False)\n",
    "\n",
    "    Order_Date_With_Trip_DF = \\\n",
    "        pd.read_sql_query('select Order_Date, trip_id, expected_start_date, Actual_end_date \\\n",
    "                            from \\\n",
    "                            ( \\\n",
    "                                select o.*, t.id as trip_id, t.expected_start_date, t.Actual_End_Date, \\\n",
    "                                row_number() over(partition by o.Order_Date order by t.expected_start_date asc) as trip_rank \\\n",
    "                                from  bi_project_db.temp o \\\n",
    "                                left join bi_project_db.trip t on o.order_date < t.expected_start_date \\\n",
    "                            ) a \\\n",
    "                            where trip_rank = 2;', \\\n",
    "                pandas_conn)\n",
    "    #for each order, assign a trip that has an expected_start_date greater than the order date. because there are many trips \n",
    "    #that will have expected_start_date greater than the order date, get only the second trip using the \n",
    "    #row_number() window function. make sure that there are trips created ahead of the order date, because if there arent any,\n",
    "    #the query will not return a result, no trip_id will be assigned to the order, so the function will return an error\n",
    "    #that all arrays must have the same length/index. that's why i made the default parameter for the function Create_Trips()\n",
    "    #to be current_date + 1 day, given that the function Create_Orders() is current_date only. so there will be trips 1 day\n",
    "    #ahead of the orders.\n",
    "\n",
    "\n",
    "    Order_Method_IDs = pd.read_sql_query('select id from order_method', pandas_conn)\n",
    "    Order_Method_IDs = Order_Method_IDs['id'].to_list()\n",
    "\n",
    "    Payment_Type_IDs = pd.read_sql_query('select id from payment_type', pandas_conn)\n",
    "    Payment_Type_IDs = Payment_Type_IDs['id'].to_list()\n",
    "\n",
    "    Employee_IDs = pd.read_sql_query('select id from employee', pandas_conn)\n",
    "    Employee_IDs = Employee_IDs['id'].to_list()\n",
    "\n",
    "    Customer_IDs = pd.read_sql_query('select id from customer', pandas_conn)\n",
    "    Customer_IDs = Customer_IDs['id'].to_list()\n",
    "\n",
    "\n",
    "    Order_Date = Order_Date_With_Trip_DF['Order_Date'].to_list()\n",
    "\n",
    "    Order_Method_ID = [random.choice(Order_Method_IDs) for i in range(Number_Of_Orders)]\n",
    "\n",
    "    Payment_Type_ID = [random.choice(Payment_Type_IDs) for i in range(Number_Of_Orders)]\n",
    "\n",
    "    Order_Gross_Amount = [0 for i in range(Number_Of_Orders)] #set as 0 until lines are created. then this value will be updated\n",
    "    #using the function Add_Order_Amount()\n",
    "\n",
    "    Order_Net_Amount = [0 for i in range(Number_Of_Orders)] #set as 0 until lines are created. then this value will be updated\n",
    "    #using the function Add_Order_Amount()\n",
    "\n",
    "    CustomerID = [random.choice(Customer_IDs) for i in range(Number_Of_Orders)]\n",
    "\n",
    "    EmployeeID = [random.choice(Employee_IDs) for i in range(Number_Of_Orders)]\n",
    "\n",
    "    TripID = Order_Date_With_Trip_DF['trip_id'].to_list()\n",
    "\n",
    "    Rating = [random.choice(Ratings_List) for i in range(Number_Of_Orders)]\n",
    "\n",
    "    Expected_Delivery_Date = Order_Date_With_Trip_DF['expected_start_date'].to_list()\n",
    "\n",
    "    Actual_Delivery_Date = Order_Date_With_Trip_DF['Actual_end_date'].to_list()\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'Order_Date' : Order_Date, 'Order_Method_ID': Order_Method_ID, 'Payment_Type_ID': Payment_Type_ID, \\\n",
    "            'Order_Gross_Amount': Order_Gross_Amount, 'Order_Net_Amount': Order_Net_Amount,\n",
    "            'CustomerID': CustomerID, 'EmployeeID': EmployeeID, 'TripID': TripID, \n",
    "            'Rating': Rating, 'Expected_Delivery_Date': Expected_Delivery_Date, \n",
    "            'Actual_Delivery_Date': Actual_Delivery_Date\n",
    "          }\n",
    "\n",
    "    Sales_Order_DF = pd.DataFrame(Dic)\n",
    "    \n",
    "    return Sales_Order_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function takes the orders DF as an input. it does not return anything.\n",
    "\n",
    "def Insert_Orders(Sales_Order_DF):\n",
    "\n",
    "    if Sales_Order_DF is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        cols_list = Sales_Order_DF.columns.to_list()\n",
    "        list_to_string = ', '.join(cols_list)\n",
    "        columns = '(' + list_to_string + ')'\n",
    "        Insert_String = 'insert into bi_project_db.sales_order \\n ' \\\n",
    "        +  columns  + '\\n' + \\\n",
    "        'Values (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'\n",
    "\n",
    "        conn = mysql.connector.connect(\n",
    "                                        host='localhost',\n",
    "                                        database='bi_project_db',\n",
    "                                        user='root',\n",
    "                                        password='root'\n",
    "                                       )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "        for index, record in Sales_Order_DF.iterrows():\n",
    "            cursor.execute(Insert_String, tuple(record))\n",
    "            conn.commit()\n",
    "\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create order lines for an order_id. it takes an order id as an input parameter. it returns an order lines dataframe\n",
    "\n",
    "def Create_Order_Line(Order_Number):\n",
    "    Order_Lines_List = [1,2,3,4,5]\n",
    "    Number_Of_Lines = random.choice(Order_Lines_List)\n",
    "\n",
    "    Products_DF = pd.read_sql_query('select id, selling_price from product', pandas_conn)\n",
    "    Product_IDs = Products_DF['id'].to_list()\n",
    "    ProductID = random.sample(Product_IDs,Number_Of_Lines) #generates unique product_ids. this makes sure that each order line\n",
    "    #will have a unique product_id. in other words, a product_id will not be repeated in more than one line of the same order\n",
    "    ProductID_DF = pd.DataFrame(ProductID, columns = ['Product_ID'])\n",
    "    Products_With_Price_DF = ProductID_DF.merge(Products_DF, how='left', left_on = 'Product_ID', right_on = 'id')\n",
    "    Products_With_Price_DF = Products_With_Price_DF[['id','selling_price']]\n",
    "\n",
    "    Promotions_DF = pd.read_sql_query('select id, amount from promotion', pandas_conn)\n",
    "    Promotion_IDs = Promotions_DF['id'].to_list()\n",
    "    PromotionID = [random.choice(Promotion_IDs) for i in range(Number_Of_Lines)]\n",
    "    PromotionID_DF = pd.DataFrame(PromotionID, columns = ['Promotion_ID'])\n",
    "    Promotion_With_Amount_DF = PromotionID_DF.merge(Promotions_DF, how='left', left_on = 'Promotion_ID', right_on = 'id')\n",
    "    Promotion_With_Amount_DF = Promotion_With_Amount_DF[['id','amount']]\n",
    "    Promotion_With_Amount_DF.rename(columns = {'id':'promotion_id'},inplace = True)\n",
    "\n",
    "    Quantity_Sold = [random.choice([1,2,3]) for i in range(Number_Of_Lines)]\n",
    "    Quantity_Sold_DF = pd.DataFrame(Quantity_Sold, columns = ['Quantity'])\n",
    "\n",
    "    Products_With_Price_And_Qty_DF = Products_With_Price_DF.join(Quantity_Sold_DF)\n",
    "\n",
    "    Products_With_Price_And_Qty_DF\n",
    "    Products_With_Price_And_Qty_And_Promotion_DF = Products_With_Price_And_Qty_DF.join(Promotion_With_Amount_DF)\n",
    "    Products_With_Price_And_Qty_And_Promotion_DF\n",
    "    Final_DF = Products_With_Price_And_Qty_And_Promotion_DF[['id','selling_price','Quantity','promotion_id','amount']]\n",
    "\n",
    "    Final_DF['Net_Amount'] = Final_DF['selling_price'] * (1 - Final_DF['amount']) * Final_DF['Quantity']\n",
    "    Net_Amount = Final_DF['Net_Amount'].to_list() #1 - the promotion amount * selling_price to get the price after the promotion\n",
    "\n",
    "    Final_DF['Gross_Amount'] = Final_DF['selling_price'] * Final_DF['Quantity']\n",
    "    Gross_Amount = Final_DF['Gross_Amount'].to_list()\n",
    "\n",
    "\n",
    "    OrderID = [Order_Number for line in range(Number_Of_Lines)]\n",
    "\n",
    "    Order_Line_Number = [i for i in range(1, Number_Of_Lines + 1)] #start creating line numbers from 1\n",
    "\n",
    "    ProductID = ProductID\n",
    "\n",
    "    PromotionID = PromotionID\n",
    "\n",
    "    Quantity_Sold = [random.choice([1,2,3]) for i in range(Number_Of_Lines)]\n",
    "\n",
    "    Net_Amount = Net_Amount\n",
    "\n",
    "    Gross_Amount = Gross_Amount\n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'OrderID' : OrderID, 'Order_Line_Number': Order_Line_Number, 'ProductID': ProductID, \\\n",
    "            'PromotionID': PromotionID, 'Quantity_Sold': Quantity_Sold,\n",
    "            'Net_Amount': Net_Amount, 'Gross_Amount': Gross_Amount\n",
    "          }\n",
    "\n",
    "    Sales_Order_Details_DF = pd.DataFrame(Dic)\n",
    "    \n",
    "    return Sales_Order_Details_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get orders that do not have order lines. this function does not have any input parameters.\n",
    "#it just checks if an order has order lines, if it doesnt, it will call the function Create_Order_Line().\n",
    "#the function Order_Line_Check() will return all order lines of orders that did not have lines all combined into one DF\n",
    "\n",
    "def Order_Line_Check():\n",
    "    \n",
    "    create_order_lines_df = \\\n",
    "    pd.read_sql_query(\n",
    "        'select id from bi_project_db.sales_order where id not in (select orderid from bi_project_db.sales_order_details)', \\\n",
    "            pandas_conn)\n",
    "\n",
    "    order_numbers = create_order_lines_df['id'].to_list()\n",
    "\n",
    "    DF_List = []\n",
    "    df = pd.DataFrame() #create an empty DF to be able to use the function pd.concat() because it accepts atleast 2 DF's\n",
    "    #if only 1 order does not have lines, 1 DF is created. + the empty DF, so total 2 DFs. so pd.concat() will not \n",
    "    #raise an error\n",
    "    DF_List.append(df)\n",
    "    \n",
    "    for order_number in order_numbers:\n",
    "        DF = Create_Order_Line(order_number)\n",
    "        DF_List.append(DF)\n",
    "    \n",
    "    if len(DF_List) >= 2: #if there are no order that do not have lines, no order lines will be created, so only 1 DF\n",
    "        #is created which is the empty DF from pd.DataFrame(), so len(DF_List) will not meet the condition >=2 so\n",
    "        #the code will not continue execution\n",
    "        all_orders_df = pd.concat(DF_List)\n",
    "        return all_orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert order lines. this function takes the order lines DF as an input. it does not return anything.\n",
    "\n",
    "def Insert_Order_Lines(Orders_DF):\n",
    "    \n",
    "    if Orders_DF is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "\n",
    "        cols_list = Orders_DF.columns.to_list()\n",
    "        list_to_string = ', '.join(cols_list)\n",
    "        columns = '(' + list_to_string + ')'\n",
    "        Insert_String = 'insert into bi_project_db.sales_order_details \\n ' \\\n",
    "        +  columns  + '\\n' + \\\n",
    "        'Values (%s, %s, %s, %s, %s, %s, %s)'\n",
    "\n",
    "        conn = mysql.connector.connect(\n",
    "                                        host='localhost',\n",
    "                                        database='bi_project_db',\n",
    "                                        user='root',\n",
    "                                        password='root'\n",
    "                                       )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "        for index, record in Orders_DF.iterrows():\n",
    "            cursor.execute(Insert_String, tuple(record))\n",
    "            conn.commit()\n",
    "\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add net and gross amount to orders with newly created lines. the function does not accept any parameters and does not \n",
    "#return anyhing\n",
    "\n",
    "def Add_Order_Amount():\n",
    "    \n",
    "    orders_with_no_amount_df = \\\n",
    "    pd.read_sql_query(\n",
    "        'select * \\\n",
    "        from bi_project_db.sales_order_details a\\\n",
    "        inner join bi_project_db.sales_order b on a.orderid = b.id \\\n",
    "            and order_net_amount = 0', \\\n",
    "            pandas_conn)\n",
    "    #get sales order details of orders that have an amount = 0.\n",
    "    \n",
    "    if orders_with_no_amount_df.empty == True:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        amount_by_order = orders_with_no_amount_df.pivot_table(values = ['Net_Amount', 'Gross_Amount'],\n",
    "                                                 index = 'OrderID', aggfunc = 'sum').reset_index()\n",
    "\n",
    "        #aggregate the line amount by order_id to get amount by order\n",
    "        \n",
    "        amount_by_order.to_sql(name = 'temp', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                                   index = False)\n",
    "\n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                                 database='bi_project_db',\n",
    "                                                 user='root',\n",
    "                                                 password='root'\n",
    "                                      )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        sql_statement = 'UPDATE sales_order \\\n",
    "               inner join temp ON (sales_order.id = temp.OrderID) \\\n",
    "               SET sales_order.Order_Gross_Amount = temp.Gross_Amount, \\\n",
    "               sales_order.Order_Net_Amount = temp.Net_Amount;'\n",
    "\n",
    "        cursor.execute(sql_statement)\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update order trip end date if the trip has an actual_end_date\n",
    "#the function does not have input parameters and does not return anything\n",
    "\n",
    "def Update_Order_Actual_Delivery_Date():\n",
    "\n",
    "    Orders_DF = pd.read_sql_query('select * from Sales_Order where actual_delivery_date is null', pandas_conn)\n",
    "    \n",
    "    if Orders_DF.empty == True:\n",
    "        pass\n",
    "    \n",
    "    else:  \n",
    "\n",
    "        Trips_DF = pd.read_sql_query('select id, Actual_End_Date from trip where Actual_End_Date is not null', pandas_conn)\n",
    "\n",
    "        order_with_trip_df = Orders_DF.merge(Trips_DF, how='inner', left_on = 'TripID', right_on = 'id')\n",
    "\n",
    "        order_with_trip_df = order_with_trip_df[['ID', 'TripID', 'Actual_End_Date']]\n",
    "\n",
    "        order_with_trip_df.to_sql(name = 'temp', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                                   index = False)\n",
    "\n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                                 database='bi_project_db',\n",
    "                                                 user='root',\n",
    "                                                 password='root'\n",
    "                                      )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        sql_statement = 'UPDATE Sales_Order \\\n",
    "               inner join temp ON (Sales_Order.ID = temp.ID) \\\n",
    "               SET Sales_Order.Actual_Delivery_Date = temp.Actual_End_Date;'\n",
    "\n",
    "        cursor.execute(sql_statement)\n",
    "        conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick randomly records from the sales_order_details table where the order_date is in the last 14 days, and set this record\n",
    "#as a return transaction in the retuns table.\n",
    "#this function get the order_date as an input. it returns return lines transactions. \n",
    "#if the return lines records are >= 10% from the total sales orders lines, no new return lines will be created.\n",
    "\n",
    "def Create_Return_Lines(P_Date = date.today()):\n",
    "\n",
    "    query_string = 'select round((select count(*) from returns) / (select count(*) from sales_order_details) * 100,0);'\n",
    "\n",
    "    return_lines = pd.read_sql_query(query_string, pandas_conn)\n",
    "    return_lines = return_lines.iloc[0,0]\n",
    "\n",
    "    if return_lines >= 10:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        Numbers_Of_Return_Lines_List = [1,2,3]\n",
    "        #max of 3 return lines because a minimum of 3 order lines can be created. 3 orders (from the function Create_Orders() )\n",
    "        #X 1 line (from the function Create_Order_Line()) each. the number of returns lines cant\n",
    "        #exceed the minimum number of order lines or an error will be raised.\n",
    "\n",
    "        Number_Of_Return_Lines = random.choice(Numbers_Of_Return_Lines_List)\n",
    "\n",
    "        Return_Reason_DF = pd.read_sql_query('select id from return_reason', pandas_conn)\n",
    "        Return_Reason_IDs = Return_Reason_DF['id'].to_list()\n",
    "        Return_ReasonID = [random.choice(Return_Reason_IDs) for i in range(Number_Of_Return_Lines)]\n",
    "\n",
    "        sales_order_lines = \\\n",
    "        pd.read_sql_query(\n",
    "        'select a.id, a.quantity_sold, a.net_amount \\\n",
    "        from bi_project_db.sales_order_details a \\\n",
    "        left join sales_order o on o.id = a.OrderID \\\n",
    "        where a.id not in \\\n",
    "        (select order_detailsid from bi_project_db.returns) \\\n",
    "        and o.Order_Date between \\\n",
    "        DATE_ADD(' + '\\'' + str(P_Date) + '\\'' + ', INTERVAL -14 DAY) and ' + '\\'' + str(P_Date) + '\\'' + ';', \\\n",
    "                pandas_conn)\n",
    "        #get sales order detail lines that are not in the returns table and the order_date must be 14 days with the order_date\n",
    "\n",
    "        Sales_Order_Line_IDs_List = sales_order_lines['id'].to_list()\n",
    "\n",
    "        if len(Sales_Order_Line_IDs_List) <= 3: #if there are only 3 records, do not continue execution or else an\n",
    "            #error will be raised if the lines are only 2.\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            Sales_Order_Line_IDs = random.sample(Sales_Order_Line_IDs_List, Number_Of_Return_Lines)\n",
    "            Sales_Order_Line_IDs_DF = pd.DataFrame(Sales_Order_Line_IDs, columns = ['Sales_Order_Line_ID'])\n",
    "\n",
    "            Sales_Order_Line_IDs_With_Qty_And_Amount = \\\n",
    "                Sales_Order_Line_IDs_DF.merge(sales_order_lines, how='left', left_on = 'Sales_Order_Line_ID', right_on = 'id')\n",
    "            Sales_Order_Line_IDs_With_Qty_And_Amount = \\\n",
    "                Sales_Order_Line_IDs_With_Qty_And_Amount[['Sales_Order_Line_ID','quantity_sold','net_amount']]\n",
    "\n",
    "\n",
    "\n",
    "            Sales_Order_Line_IDs = Sales_Order_Line_IDs_With_Qty_And_Amount['Sales_Order_Line_ID'].to_list()\n",
    "\n",
    "            Return_ReasonID = Return_ReasonID\n",
    "\n",
    "            Returned_Quantity = Sales_Order_Line_IDs_With_Qty_And_Amount['quantity_sold'].to_list()\n",
    "\n",
    "            Returned_Amount = Sales_Order_Line_IDs_With_Qty_And_Amount['net_amount'].to_list()\n",
    "\n",
    "            Return_Date = [datetime.now() for i in range(Number_Of_Return_Lines)]\n",
    "\n",
    "\n",
    "            Dic = {\n",
    "                    'Order_DetailsID' : Sales_Order_Line_IDs, 'Return_ReasonID': Return_ReasonID, \\\n",
    "                    'Returned_Quantity': Returned_Quantity, 'Returned_Amount': Returned_Amount, \\\n",
    "                    'Return_Date': Return_Date\n",
    "                   }\n",
    "\n",
    "\n",
    "\n",
    "            Returns_DF = pd.DataFrame(Dic)\n",
    "\n",
    "            return Returns_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert return lines. this function takes the return lines DF as an input. it does not return anything.\n",
    "def Insert_Return_Lines(Returns_DF):\n",
    "\n",
    "    if Returns_DF is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "\n",
    "        cols_list = Returns_DF.columns.to_list()\n",
    "        list_to_string = ', '.join(cols_list)\n",
    "        columns = '(' + list_to_string + ')'\n",
    "        Insert_String = 'insert into bi_project_db.returns \\n ' \\\n",
    "        +  columns  + '\\n' + \\\n",
    "        'Values (%s, %s, %s, %s, %s)'\n",
    "\n",
    "        conn = mysql.connector.connect(\n",
    "                                        host='localhost',\n",
    "                                        database='bi_project_db',\n",
    "                                        user='root',\n",
    "                                        password='root'\n",
    "                                       )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "        for index, record in Returns_DF.iterrows():\n",
    "            cursor.execute(Insert_String, tuple(record))\n",
    "            conn.commit()\n",
    "\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purchase_Order And Purchase_Order_Details Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new purchase orders. #this function creates new purchase orders for the entered date. \n",
    "#it takes an input parameter as the order date. \n",
    "#current_date is the default parameter. #the function returns a dataframe with the purchase order information\n",
    "#a maximum of 2 purchase orders are created each day\n",
    "\n",
    "def Create_Purchase_Order(P_Date = date.today()):\n",
    "    \n",
    "    query_string = 'select count(*) \\\n",
    "             from bi_project_db.purchase_order \\\n",
    "             where cast(order_date as date) = ' + '\\'' + str(P_Date) + '\\''\n",
    "\n",
    "    Purchase_Orders = pd.read_sql_query(query_string, pandas_conn)\n",
    "    Purchase_Orders = Purchase_Orders.iloc[0,0]\n",
    "\n",
    "    if Purchase_Orders < 2:\n",
    "    \n",
    "    \n",
    "        Number_Of_Orders = 1\n",
    "\n",
    "        Hours_List = list(range(0,24))\n",
    "        Mins_Secs_List = list(range(1,60))\n",
    "\n",
    "        Rand_Hr = str(random.choice(Hours_List))\n",
    "        Rand_Min = str(random.choice(Mins_Secs_List))\n",
    "        Rand_Sec = str(random.choice(Mins_Secs_List))\n",
    "        Order_Date = datetime.strptime(str(P_Date) + ' ' + Rand_Hr + ':' + Rand_Min + ':' + Rand_Sec ,'%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        Supplier_IDs = pd.read_sql_query('select id from supplier', pandas_conn)\n",
    "        Supplier_IDs = Supplier_IDs['id'].to_list()\n",
    "        SupplierID = random.choice(Supplier_IDs)\n",
    "\n",
    "        Employee_IDs = pd.read_sql_query('select id from employee', pandas_conn)\n",
    "        Employee_IDs = Employee_IDs['id'].to_list()\n",
    "        EmployeeID = random.choice(Employee_IDs)\n",
    "\n",
    "\n",
    "        #since only one purchase order will be created per each function run, there is no need to create a list\n",
    "        #similar to what was done before in the other functions\n",
    "        \n",
    "        Order_Date = Order_Date\n",
    "\n",
    "        Expected_Arrival_Date = Order_Date + timedelta(days = random.choice(list(range(3,9))))\n",
    "\n",
    "        Order_Value = 0\n",
    "\n",
    "        SupplierID = SupplierID\n",
    "\n",
    "        BranchID = 3\n",
    "\n",
    "        EmployeeID = EmployeeID\n",
    "\n",
    "\n",
    "\n",
    "        Dic = {\n",
    "        'Order_Date' : Order_Date, 'Expected_Arrival_Date': Expected_Arrival_Date, 'Order_Value': Order_Value, \\\n",
    "        'SupplierID': SupplierID, 'BranchID': BranchID, 'EmployeeID': EmployeeID\n",
    "        }\n",
    "\n",
    "        Purchase_Order_DF = pd.DataFrame(Dic, index=[0])\n",
    "\n",
    "        return Purchase_Order_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function takes the purchase orders DF as an input. it does not return anything.\n",
    "\n",
    "def Insert_Purchase_Orders(Purchase_Order_DF):\n",
    "    \n",
    "    if Purchase_Order_DF is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "    \n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                        database='bi_project_db',\n",
    "                                        user='root',\n",
    "                                        password='root'\n",
    "                                        )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        cols_list = Purchase_Order_DF.columns.to_list()\n",
    "        list_to_string = ', '.join(cols_list)\n",
    "        columns = '(' + list_to_string + ')'\n",
    "        Insert_String = 'insert into bi_project_db.purchase_order \\n ' \\\n",
    "        +  columns  + '\\n' + \\\n",
    "        'Values (%s, %s, %s, %s, %s, %s)'\n",
    "\n",
    "        for index, record in Purchase_Order_DF.iterrows():\n",
    "            cursor.execute(Insert_String, tuple(record))\n",
    "            conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create purchase order lines for each purchase_order_id. it takes a purchase_order_id as an input parameter.\n",
    "#it returns a purchase order lines dataframe\n",
    "\n",
    "def Create_Purchase_Order_Line(PO_Number):\n",
    "    Order_Lines_List = [1,2,3]\n",
    "    Number_Of_Lines = random.choice(Order_Lines_List)\n",
    "\n",
    "    Raw_Materials_DF = pd.read_sql_query('select id, cost_price from Raw_Material', pandas_conn)\n",
    "    Raw_Material_IDs = Raw_Materials_DF['id'].to_list()\n",
    "    Raw_MaterialID = random.sample(Raw_Material_IDs, Number_Of_Lines) #generates unique raw_material_ids. \n",
    "    #this makes sure that each purchase order line will have a unique raw_material_id. in other words,\n",
    "    #a raw_material_id will not be repeated in more than one line of the same purchase order\n",
    "    Raw_MaterialID_DF = pd.DataFrame(Raw_MaterialID, columns = ['Raw_Material_ID'])\n",
    "    Raw_Materials_With_Price_DF = Raw_MaterialID_DF.merge(Raw_Materials_DF, how='left', \n",
    "                                                          left_on = 'Raw_Material_ID', right_on = 'id')\n",
    "    Raw_Materials_With_Price_DF = Raw_Materials_With_Price_DF[['id','cost_price']]\n",
    "\n",
    "\n",
    "    Ordered_Quantity = [random.choice(list(range(30,50))) for i in range(Number_Of_Lines)]\n",
    "    Ordered_Quantity_DF = pd.DataFrame(Ordered_Quantity, columns = ['Quantity'])\n",
    "\n",
    "    Final_DF = Raw_Materials_With_Price_DF.join(Ordered_Quantity_DF)\n",
    "\n",
    "    Final_DF['Ordered_Value'] = Final_DF['cost_price']  * Final_DF['Quantity']\n",
    "    Ordered_Value = Final_DF['Ordered_Value'].to_list()\n",
    "\n",
    "\n",
    "    Purchase_OrderID = [PO_Number for line in range(Number_Of_Lines)]\n",
    "\n",
    "    Line_Number = [i for i in range(1, Number_Of_Lines + 1)]\n",
    "\n",
    "    Raw_MaterialID = Raw_MaterialID\n",
    "\n",
    "    Ordered_Quantity = Ordered_Quantity\n",
    "\n",
    "    Ordered_Value = Ordered_Value   \n",
    "\n",
    "\n",
    "    Dic = {\n",
    "            'Purchase_OrderID' : Purchase_OrderID, 'Line_Number': Line_Number, 'Raw_MaterialID': Raw_MaterialID, \\\n",
    "            'Ordered_Quantity': Ordered_Quantity, 'Ordered_Value': Ordered_Value\n",
    "          }\n",
    "\n",
    "    Purchase_Order_Details_DF = pd.DataFrame(Dic)\n",
    "    \n",
    "    return Purchase_Order_Details_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get purchase orders that do not have order lines. this function does not have any input parameters.\n",
    "#it just checks if a purchase order has order lines, if it doesnt, it will call the function Create_Purchase_Order_Line().\n",
    "#the function Purchase_Order_Line_Check() will return all order lines of orders that did not have lines all combined into one DF\n",
    "\n",
    "def Purchase_Order_Line_Check():\n",
    "    \n",
    "    create_order_lines_df = \\\n",
    "    pd.read_sql_query(\n",
    "        'select id from bi_project_db.purchase_order where id not in \\\n",
    "        (select Purchase_orderid from bi_project_db.purchase_order_details)', \\\n",
    "            pandas_conn)\n",
    "\n",
    "    order_numbers = create_order_lines_df['id'].to_list()\n",
    "\n",
    "    DF_List = []\n",
    "    df = pd.DataFrame()\n",
    "    DF_List.append(df)\n",
    "    \n",
    "    for order_number in order_numbers:\n",
    "        DF = Create_Purchase_Order_Line(order_number)\n",
    "        DF_List.append(DF)\n",
    "    \n",
    "    if len(DF_List) >= 2:\n",
    "        purchase_orders_df = pd.concat(DF_List)\n",
    "        return purchase_orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert purchase order lines. this function takes the purchase order lines DF as an input. it does not return anything.\n",
    "\n",
    "def Insert_Purchase_Order_Lines(Purchase_Orders_DF):\n",
    "    \n",
    "    if Purchase_Orders_DF is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "\n",
    "        cols_list = Purchase_Orders_DF.columns.to_list()\n",
    "        list_to_string = ', '.join(cols_list)\n",
    "        columns = '(' + list_to_string + ')'\n",
    "        Insert_String = 'insert into bi_project_db.purchase_order_details \\n ' \\\n",
    "        +  columns  + '\\n' + \\\n",
    "        'Values (%s, %s, %s, %s, %s)'\n",
    "\n",
    "        conn = mysql.connector.connect(\n",
    "                                        host='localhost',\n",
    "                                        database='bi_project_db',\n",
    "                                        user='root',\n",
    "                                        password='root'\n",
    "                                       )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "        for index, record in Purchase_Orders_DF.iterrows():\n",
    "            cursor.execute(Insert_String, tuple(record))\n",
    "            conn.commit()\n",
    "\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add value to purchase orders with newly created lines. #the function does not accept any parameters and does not \n",
    "#return anyhing\n",
    "\n",
    "def Add_Purchase_Order_Value():\n",
    "    \n",
    "    orders_with_no_amount_df = \\\n",
    "    pd.read_sql_query(\n",
    "        'select * \\\n",
    "        from bi_project_db.purchase_order_details a\\\n",
    "        inner join bi_project_db.purchase_order b on a.purchase_orderid = b.id \\\n",
    "            and order_value = 0', \\\n",
    "            pandas_conn)\n",
    "    \n",
    "    #get purchase order lines of purchase orders that have a value of 0\n",
    "    \n",
    "    if orders_with_no_amount_df.empty == True:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        amount_by_order = orders_with_no_amount_df.pivot_table(values = ['Ordered_Value'],\n",
    "                                                 index = 'Purchase_OrderID', aggfunc = 'sum').reset_index()\n",
    "\n",
    "        amount_by_order.to_sql(name = 'temp', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                                   index = False)\n",
    "\n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                                 database='bi_project_db',\n",
    "                                                 user='root',\n",
    "                                                 password='root'\n",
    "                                      )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        sql_statement = 'UPDATE purchase_order \\\n",
    "               inner join temp ON (purchase_order.id = temp.Purchase_OrderID) \\\n",
    "               SET purchase_order.Order_value = temp.Ordered_Value;'\n",
    "\n",
    "        cursor.execute(sql_statement)\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoice And Invoice_Details Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this functions checks if there are purchase orders that do not have invoices. it does not accept any input parameters.\n",
    "#the function returns invoices dataframe for each purchase order\n",
    "\n",
    "#business rules for creating invoices:\n",
    "#for each PO\n",
    "#get the dates range between the (order_date + 1 day) and the (expected_arrival_date + a random of -1 to 2 days)\n",
    "#this dates range will be used to get the invoices for each PO.\n",
    "#the number of invoices for each PO will be a random number of the difference between the\n",
    "#PO order_date and the expected_delivery_date\n",
    "\n",
    "\n",
    "\n",
    "def Create_PO_Invoices():\n",
    "    \n",
    "    \n",
    "    #get purchase orders that do not have invoices\n",
    "    \n",
    "    PO = \\\n",
    "    pd.read_sql_query(\n",
    "    'select id, order_date, expected_arrival_date, \\\n",
    "    datediff(expected_arrival_date, order_date) as diff \\\n",
    "    from bi_project_db.purchase_order \\\n",
    "    where id not in \\\n",
    "    (select purchase_orderid from invoice);', \n",
    "            pandas_conn)\n",
    "\n",
    "    \n",
    "    if PO.empty == True:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        PO['invoices_start_interval'] = PO['order_date'].apply(lambda x: x + timedelta(days = 1))\n",
    "        PO['invoices_end_interval'] = PO['expected_arrival_date'].apply(lambda x: x + timedelta(days = \\\n",
    "                                                                                        random.choice([-1,0,1,2])))\n",
    "        PO['no_of_invoices'] = PO['diff'].apply(lambda x: random.choice(range(1,x)))\n",
    "\n",
    "\n",
    "        Employees = pd.read_sql_query('select id from employee', pandas_conn)\n",
    "        Employees = Employees['id'].to_list()\n",
    "\n",
    "        order_invoices_list = []\n",
    "\n",
    "        \n",
    "        #for each PO, get its ID, the start and end_date intervals so that it will be used to create invoice dates, the number\n",
    "        #of invoices\n",
    "        \n",
    "        \n",
    "        for index, row in PO.iterrows():\n",
    "            po_id = row['id']\n",
    "            start_date = row['invoices_start_interval'] \n",
    "            end_date = row['invoices_end_interval']\n",
    "            no_of_invoices = row['no_of_invoices']\n",
    "            dates_list = pd.date_range(start_date, end_date).to_list()\n",
    "            invoice_dates = sorted(random.sample(dates_list, no_of_invoices)) \n",
    "            #to make sure that each date is picked only once. random.sample returns a list. this list will be sorted\n",
    "            #so that dates will be assigned from smallest to biggest as each invoice ID is created.\n",
    "            #this makes sure that invoice_id 1 has a smaller invoice date compared to invoice_date 2\n",
    "            \n",
    "\n",
    "            #loop on the number of invoices for each PO and generate an invoice date in order based on the dates range \n",
    "            #in tge date_list\n",
    "            for invoice in range(no_of_invoices):\n",
    "                order_invoices_list.append([invoice_dates[invoice], 0, po_id, random.choice(Employees)])\n",
    "                #the 0 is the invoice amount. it will be updated using the function Add_Invoice_Value()\n",
    "\n",
    "        invoices_df = pd.DataFrame(order_invoices_list, columns = ['Date','Invoice_Amount', 'Purchase_OrderID', 'EmployeeID']) \n",
    "\n",
    "        return invoices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert invoices. this function takes the invoices DF as an input. it does not return anything.\n",
    "\n",
    "def Insert_Invoices(Invoices_DF):\n",
    "    \n",
    "    if Invoices_DF is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "    \n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                        database='bi_project_db',\n",
    "                                        user='root',\n",
    "                                        password='root'\n",
    "                                        )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        cols_list = Invoices_DF.columns.to_list()\n",
    "        list_to_string = ', '.join(cols_list)\n",
    "        columns = '(' + list_to_string + ')'\n",
    "        Insert_String = 'insert into bi_project_db.invoice \\n ' \\\n",
    "        +  columns  + '\\n' + \\\n",
    "        'Values (%s, %s, %s, %s)'\n",
    "\n",
    "        for index, record in Invoices_DF.iterrows():\n",
    "            cursor.execute(Insert_String, tuple(record))\n",
    "            conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function checks for invoices that do not have lines, and returns invoice lines DF. the function does not accept input\n",
    "#parameters.\n",
    "\n",
    "#business rules for creating invoice lines:\n",
    "#for every PO, get the number of invoices.\n",
    "#for every PO, get the lines.\n",
    "#for every PO line, divide the quantity of each line by the number of invoices.\n",
    "#this will be the invoice line\n",
    "#when dividing the quantity of each purchase order line by the number of invoices, the remaining will be added to \n",
    "#the last invoice\n",
    "#for example, if a PO line has quantity  = 5, and the number of invoices is 2, so each invoice line will have\n",
    "#quantity = 2 (5/2). however, there will be 1 remaining quantity, this will be added to the last invoice. so the first invoice\n",
    "#will have quantity of 2, the second invoice which is the last invoice will have a quantity of 3.\n",
    "#the sum of each raw_material quantity in the PO line should equal the raw_material quantity in the invoice lines\n",
    "\n",
    "def Create_Invoice_Lines():\n",
    "\n",
    "\n",
    "    #get invoices that do not have lines\n",
    "    Invoices_Without_Lines = \\\n",
    "        pd.read_sql_query(\n",
    "        'select id as invoice_id, Purchase_orderid \\\n",
    "        from invoice \\\n",
    "        where id not in \\\n",
    "        (select invoiceid from invoice_details);', \n",
    "                pandas_conn)\n",
    "\n",
    "    \n",
    "    if Invoices_Without_Lines.empty == True:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "\n",
    "        #get the number of invoices for each PO\n",
    "\n",
    "        Invoices_By_PO = Invoices_Without_Lines.pivot_table(values = ['invoice_id'],\n",
    "                                                         index = 'Purchase_orderid', aggfunc = 'count').reset_index()\n",
    "        Invoices_By_PO.rename(columns = {'invoice_id' : 'Num_Of_Invoices'}, inplace = True)\n",
    "\n",
    "        Invoices_By_PO.to_sql(name = 'temp', con = pandas_conn, schema = 'bi_project_db', \n",
    "                              if_exists = 'replace', index = False)\n",
    "\n",
    "\n",
    "        invoice_lines = \\\n",
    "            pd.read_sql_query(\n",
    "            'select b.*, a.Num_Of_Invoices, floor(b.Ordered_Quantity/a.Num_Of_Invoices) as inv_qty, \\\n",
    "            floor(b.Ordered_value/a.Num_Of_Invoices) as inv_amt\\\n",
    "            from temp a \\\n",
    "            left join purchase_order_details b on \\\n",
    "            a.Purchase_orderid = b.Purchase_orderid;', \n",
    "                    pandas_conn)\n",
    "\n",
    "\n",
    "        invoice_lines_remains = invoice_lines[['Purchase_OrderID', 'Raw_MaterialID', 'Num_Of_Invoices', \n",
    "                                               'Ordered_Quantity', 'Ordered_Value']].copy()\n",
    "\n",
    "        invoice_lines_remains['remaining_qty'] = invoice_lines_remains['Ordered_Quantity'] % \\\n",
    "        invoice_lines_remains['Num_Of_Invoices']\n",
    "\n",
    "        invoice_lines_remains['remaining_amount'] = invoice_lines_remains['Ordered_Value'] % \\\n",
    "        invoice_lines_remains['Num_Of_Invoices']\n",
    "\n",
    "\n",
    "        invoice_lines = invoice_lines[['Purchase_OrderID', 'Raw_MaterialID', 'inv_qty', 'inv_amt']]\n",
    "        invoice_lines_with_inv_number = Invoices_Without_Lines.merge(invoice_lines, how='left', \n",
    "                                                                     left_on = 'Purchase_orderid', right_on = 'Purchase_OrderID')\n",
    "        invoice_lines_with_inv_number = invoice_lines_with_inv_number \\\n",
    "                                            [['invoice_id','Purchase_orderid','Raw_MaterialID','inv_qty','inv_amt']]\n",
    "\n",
    "\n",
    "        #partition by PO_id and raw material, order by the invoice_id desc\n",
    "        invoice_lines_with_inv_number['row_number'] = invoice_lines_with_inv_number.sort_values(['invoice_id'],ascending = False)\\\n",
    "                     .groupby(['Purchase_orderid', 'Raw_MaterialID'])\\\n",
    "                     .cumcount() + 1\n",
    "\n",
    "\n",
    "        #get the last invoice of each order and raw_material\n",
    "        updated_inv = invoice_lines_with_inv_number.loc[invoice_lines_with_inv_number['row_number'] == 1]\n",
    "\n",
    "        #join the previous df with the remaining quantity and value so that the last invoice qty and amount can be updated\n",
    "        updated_inv = invoice_lines_remains.merge(updated_inv, how='left', left_on = ['Purchase_OrderID', 'Raw_MaterialID']\n",
    "                                    , right_on = ['Purchase_orderid', 'Raw_MaterialID'])\n",
    "\n",
    "        #add the remaining qty and amount to the last invoice\n",
    "        updated_inv['inv_qty'] = updated_inv['inv_qty'] + updated_inv['remaining_qty'] \n",
    "        updated_inv['inv_amt'] = updated_inv['inv_amt'] + updated_inv['remaining_amount'] \n",
    "        updated_inv = updated_inv[['invoice_id', 'Purchase_orderid', 'Raw_MaterialID', 'inv_qty', 'inv_amt', 'row_number']]\n",
    "\n",
    "        \n",
    "        #join the invoice line with the remaining quantity\n",
    "        invoice_lines_with_inv_number = invoice_lines_with_inv_number.merge( \\\n",
    "            updated_inv, how='left', left_on = ['Purchase_orderid', 'Raw_MaterialID', 'invoice_id']\n",
    "                                    , right_on = ['Purchase_orderid', 'Raw_MaterialID', 'invoice_id'],\n",
    "                                     suffixes=(None, '_x')) #add suffix of _x to the DF that has the remaining Qty\n",
    "\n",
    "        \n",
    "        #update the quantity of the last invoice to include the remaining quantity\n",
    "        invoice_lines_with_inv_number.loc[invoice_lines_with_inv_number['inv_qty_x'].notnull(), 'inv_qty'] = \\\n",
    "        invoice_lines_with_inv_number['inv_qty_x']\n",
    "        invoice_lines_with_inv_number.loc[invoice_lines_with_inv_number['inv_qty_x'].notnull(), 'inv_amt'] = \\\n",
    "        invoice_lines_with_inv_number['inv_amt_x']\n",
    "\n",
    "\n",
    "        invoice_lines_with_inv_number = \\\n",
    "        invoice_lines_with_inv_number[['invoice_id','Raw_MaterialID','inv_qty','inv_amt']]\n",
    "        invoice_lines_with_inv_number.rename(columns = {'invoice_id':'InvoiceID', 'inv_qty':'Invoiced_Quantity',\\\n",
    "                                                       'inv_amt':'Invoiced_Amount'}, inplace = True)\n",
    "        return invoice_lines_with_inv_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert invoice lines. this function takes the invoice lines DF as an input. it does not return anything.\n",
    "\n",
    "def Insert_Invoice_Lines(Invoices_Lines_DF):\n",
    "    \n",
    "    if Invoices_Lines_DF is None:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "    \n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                        database='bi_project_db',\n",
    "                                        user='root',\n",
    "                                        password='root'\n",
    "                                        )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        cols_list = Invoices_Lines_DF.columns.to_list()\n",
    "        list_to_string = ', '.join(cols_list)\n",
    "        columns = '(' + list_to_string + ')'\n",
    "        Insert_String = 'insert into bi_project_db.invoice_details \\n ' \\\n",
    "        +  columns  + '\\n' + \\\n",
    "        'Values (%s, %s, %s, %s)'\n",
    "\n",
    "        for index, record in Invoices_Lines_DF.iterrows():\n",
    "            cursor.execute(Insert_String, tuple(record))\n",
    "            conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add value to invoices with newly created lines. #the function does not accept any parameters and does not \n",
    "#return anyhing\n",
    "\n",
    "def Add_Invoice_Value():\n",
    "    \n",
    "    invoices_with_no_amount_df = \\\n",
    "    pd.read_sql_query(\n",
    "        'select * \\\n",
    "        from bi_project_db.invoice_details a\\\n",
    "        inner join bi_project_db.invoice b on a.invoiceid = b.id \\\n",
    "            and invoice_amount = 0', \\\n",
    "            pandas_conn)\n",
    "    \n",
    "    if invoices_with_no_amount_df.empty == True:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        amount_by_invoice = invoices_with_no_amount_df.pivot_table(values = ['Invoiced_Amount'],\n",
    "                                                 index = 'InvoiceID', aggfunc = 'sum').reset_index()\n",
    "\n",
    "        amount_by_invoice.to_sql(name = 'temp', con = pandas_conn, schema = 'bi_project_db', if_exists = 'replace',\n",
    "                                   index = False)\n",
    "\n",
    "        conn = mysql.connector.connect(host='localhost',\n",
    "                                                 database='bi_project_db',\n",
    "                                                 user='root',\n",
    "                                                 password='root'\n",
    "                                      )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        sql_statement = 'UPDATE invoice \\\n",
    "               inner join temp ON (invoice.id = temp.InvoiceID) \\\n",
    "               SET invoice.Invoice_Amount = temp.Invoiced_Amount;'\n",
    "\n",
    "        cursor.execute(sql_statement)\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Lookup Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill Lookups\n",
    "\n",
    "Promotion()\n",
    "\n",
    "Payment_Type()\n",
    "\n",
    "Order_Method()\n",
    "\n",
    "Return_Reason()\n",
    "\n",
    "Vehicle()\n",
    "\n",
    "Product()\n",
    "\n",
    "Country()\n",
    "\n",
    "City()\n",
    "\n",
    "Area()\n",
    "\n",
    "Branch()\n",
    "\n",
    "Raw_Material()\n",
    "\n",
    "Customer()\n",
    "\n",
    "Department()\n",
    "\n",
    "Employee()\n",
    "\n",
    "Supplier()\n",
    "\n",
    "Route()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Transaction Tables For 1 Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInsert_Trips(Create_Trips())\\n\\nTrip_Actual_Start_Date()\\n\\nTrip_Actual_End_Date()\\n'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trips Cycle\n",
    "\n",
    "'''\n",
    "Insert_Trips(Create_Trips())\n",
    "\n",
    "Trip_Actual_Start_Date()\n",
    "\n",
    "Trip_Actual_End_Date()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInsert_Orders(Create_Orders())\\n\\nInsert_Order_Lines(Order_Line_Check())\\n\\nAdd_Order_Amount()\\n\\nUpdate_Order_Actual_Delivery_Date()\\n\\nInsert_Return_Lines(Create_Return_Lines())\\n'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sales Cycle\n",
    "\n",
    "'''\n",
    "Insert_Orders(Create_Orders())\n",
    "\n",
    "Insert_Order_Lines(Order_Line_Check())\n",
    "\n",
    "Add_Order_Amount()\n",
    "\n",
    "Update_Order_Actual_Delivery_Date()\n",
    "\n",
    "Insert_Return_Lines(Create_Return_Lines())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInsert_Purchase_Orders(Create_Purchase_Order())\\n\\nInsert_Purchase_Order_Lines(Purchase_Order_Line_Check())\\n\\nAdd_Purchase_Order_Value()\\n\\nInsert_Invoices(Create_PO_Invoices())\\n\\nInsert_Invoice_Lines(Create_Invoice_Lines())\\n\\nAdd_Invoice_Value()\\n'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PO Cycle\n",
    "\n",
    "'''\n",
    "Insert_Purchase_Orders(Create_Purchase_Order())\n",
    "\n",
    "Insert_Purchase_Order_Lines(Purchase_Order_Line_Check())\n",
    "\n",
    "Add_Purchase_Order_Value()\n",
    "\n",
    "Insert_Invoices(Create_PO_Invoices())\n",
    "\n",
    "Insert_Invoice_Lines(Create_Invoice_Lines())\n",
    "\n",
    "Add_Invoice_Value()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Transactional Tables For X Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Trips Data For  The Last 2 years from today\n",
    "\n",
    "def Generate_Trips_Data(start_date = date.today() - timedelta(weeks = 104),\n",
    "                        end_date = date.today() + timedelta(days = 1)):\n",
    "    \n",
    "    #start_date = date.today() - timedelta(days = 100)\n",
    "    #end_date = date.today() + timedelta(days = 1)\n",
    "\n",
    "    datetimelist = pd.date_range(start_date, end_date).tolist()\n",
    "    dateslist = [i.date() for i in datetimelist]\n",
    "\n",
    "    for date_i in dateslist:\n",
    "        Insert_Trips(Create_Trips(date_i))\n",
    "\n",
    "    Trip_Actual_Start_Date()\n",
    "    Trip_Actual_End_Date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Sales Data For  The Last 2 years from today\n",
    "\n",
    "def Generate_Sales_Data(start_date = date.today() - timedelta(weeks = 104),\n",
    "                        end_date = date.today()):\n",
    "\n",
    "\n",
    "    #start_date = date.today() - timedelta(days = 100)\n",
    "    #end_date = date.today() \n",
    "\n",
    "    datetimelist = pd.date_range(start_date, end_date).tolist()\n",
    "    dateslist = [i.date() for i in datetimelist]\n",
    "\n",
    "    for date_i in dateslist: \n",
    "        Insert_Orders(Create_Orders(date_i))\n",
    "        Insert_Order_Lines(Order_Line_Check())\n",
    "        Insert_Return_Lines(Create_Return_Lines(date_i))\n",
    "            \n",
    "    Add_Order_Amount()\n",
    "    Update_Order_Actual_Delivery_Date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Purchases Data For The Last 2 years from today\n",
    "\n",
    "def Generate_Purchases_Data(start_date = date.today() - timedelta(weeks = 104),\n",
    "                        end_date = date.today()):\n",
    "\n",
    "    #start_date = date.today() - timedelta(days = 100)\n",
    "    #end_date = date.today() \n",
    "    \n",
    "    datetimelist = pd.date_range(start_date, end_date).tolist()\n",
    "    dateslist = [i.date() for i in datetimelist]\n",
    "\n",
    "    for date_i in dateslist:\n",
    "\n",
    "        Insert_Purchase_Orders(Create_Purchase_Order(date_i))\n",
    "\n",
    "    Insert_Purchase_Order_Lines(Purchase_Order_Line_Check())\n",
    "\n",
    "    Insert_Invoices(Create_PO_Invoices())\n",
    "\n",
    "    Insert_Invoice_Lines(Create_Invoice_Lines())\n",
    "\n",
    "    Add_Purchase_Order_Value()\n",
    "\n",
    "    Add_Invoice_Value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate_Trips_Data(start_date = '2022-10-27', end_date = '2022-11-08')\n",
    "#Generate_Sales_Data(start_date = '2022-10-27', end_date = '2022-11-07')\n",
    "#Generate_Purchases_Data(start_date = '2022-10-27', end_date = '2022-11-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.8703925927480063 Minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "Generate_Trips_Data()\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print('Execution time:', elapsed_time, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 15.955285028616588 Minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "Generate_Sales_Data()\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print('Execution time:', elapsed_time, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.3053950389226276 Minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "Generate_Purchases_Data()\n",
    "end_time = time.time()\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print('Execution time:', elapsed_time, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInsert_Purchase_Orders(Create_Purchase_Order())\\n\\nInsert_Purchase_Order_Lines(Purchase_Order_Line_Check())\\n\\nAdd_Purchase_Order_Value()\\n\\nInsert_Invoices(Create_PO_Invoices())\\n\\nInsert_Invoice_Lines(Create_Invoice_Lines())\\n\\nAdd_Invoice_Value()\\n'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Insert_Purchase_Orders(Create_Purchase_Order())\n",
    "\n",
    "Insert_Purchase_Order_Lines(Purchase_Order_Line_Check())\n",
    "\n",
    "Add_Purchase_Order_Value()\n",
    "\n",
    "Insert_Invoices(Create_PO_Invoices())\n",
    "\n",
    "Insert_Invoice_Lines(Create_Invoice_Lines())\n",
    "\n",
    "Add_Invoice_Value()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
